{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import geopandas as gpd \n",
    "import pandas as pd\n",
    "from shapely import ops\n",
    "import os\n",
    "import shapely\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import pandana as pdna\n",
    "import networkx as nx\n",
    "import multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from geoalchemy2 import Geometry, WKTElement\n",
    "from sqlalchemy import *\n",
    "\n",
    "from shapely.geometry import *\n",
    "shapely.speedups.enable()\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add creating netwotk graph code\n",
    "def create_graph(gdf, precision=3, simplify=1):\n",
    "    '''Create a networkx DiGraph given a GeoDataFrame of lines. Every line will\n",
    "    correspond to two directional graph edges, one forward, one reverse. The\n",
    "    original line row and direction will be stored in each edge. Every node\n",
    "    will be where endpoints meet (determined by being very close together) and\n",
    "    will store a clockwise ordering of incoming edges.\n",
    "    '''\n",
    "    # The geometries sometimes have tiny end parts - get rid of those!\n",
    "    gdf.geometry = gdf.geom.simplify(simplify)\n",
    "\n",
    "    #G = nx.DiGraph()\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # TODO: converting to string is probably unnecessary - keeping float may be\n",
    "    # faster\n",
    "    def make_node(coord, precision):\n",
    "        return tuple(np.round(coord, precision))\n",
    "\n",
    "    # Edges are stored as (from, to, data), where from and to are nodes.\n",
    "    # az1 is the azimuth of the first segment of the geometry (point into the\n",
    "    # geometry), az2 is for the last segment (pointing out of the geometry)\n",
    "    def add_edges(row, G):\n",
    "        geom = row.geom\n",
    "        coords = list(geom.coords)\n",
    "        geom_r = LineString(coords[::-1])\n",
    "        coords_r = geom_r.coords\n",
    "        start = make_node(coords[0], precision)\n",
    "        end = make_node(coords[-1], precision)\n",
    "        # Add forward edge\n",
    "        fwd_attr ={}\n",
    "        for k,v in row.items():\n",
    "            fwd_attr[k]=v\n",
    "        fwd_attr['forward']= 1\n",
    "        fwd_attr['geometry']=  geom\n",
    "        fwd_attr['length']=  geom.length\n",
    "#         fwd_attr['az1']=  azimuth_cartesian(coords[0], coords[1])\n",
    "#         fwd_attr['az2']=  azimuth_cartesian(coords[-2], coords[-1])\n",
    "        fwd_attr['visited']= 0\n",
    "\n",
    "        G.add_edge(start, end, **fwd_attr)\n",
    "\n",
    "    gdf.apply(add_edges, axis=1, args=[G])\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         74.097267\n",
       "1         86.664696\n",
       "2         63.990661\n",
       "3         63.990661\n",
       "4         98.384042\n",
       "5         90.022112\n",
       "6         90.022112\n",
       "7         90.022112\n",
       "8         52.952604\n",
       "9         52.952604\n",
       "10        61.841117\n",
       "11        61.841117\n",
       "12        91.898827\n",
       "13        18.823190\n",
       "14        33.944756\n",
       "15        83.179815\n",
       "16        83.179815\n",
       "17        78.401199\n",
       "18        89.854370\n",
       "19        50.401166\n",
       "20        50.401166\n",
       "21        86.633939\n",
       "22        86.633939\n",
       "23        86.633939\n",
       "24        97.680349\n",
       "25        90.409356\n",
       "26        80.588990\n",
       "27        80.588990\n",
       "28        63.082536\n",
       "29        63.082536\n",
       "            ...    \n",
       "125232    78.554208\n",
       "125233    78.554208\n",
       "125234    60.643137\n",
       "125235    78.866441\n",
       "125236    57.266962\n",
       "125237    57.266962\n",
       "125238    79.303550\n",
       "125239    79.303550\n",
       "125240    84.928817\n",
       "125241    59.765053\n",
       "125242    94.719212\n",
       "125243    65.043230\n",
       "125244    65.366956\n",
       "125245    50.990459\n",
       "125246    50.990459\n",
       "125247    92.031043\n",
       "125248    53.693961\n",
       "125249    68.807735\n",
       "125250    68.807735\n",
       "125251    59.789842\n",
       "125252    59.789842\n",
       "125253    79.695762\n",
       "125254    83.000348\n",
       "125255    66.394121\n",
       "125256    66.394121\n",
       "125257    83.252441\n",
       "125258    74.316316\n",
       "125259    61.166064\n",
       "125260    61.166064\n",
       "125261    74.097267\n",
       "Name: distance, Length: 125262, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# database connection\n",
    "con = psycopg2.connect(database=\"walkability\", user=\"postgres\", password=1234,\n",
    "    host=\"****\",port=\"5432\")\n",
    "pednet= gpd.read_postgis('SELECT * FROM public.pednet100m',con,crs={'init': 'epsg:2019'})\n",
    "pednet['distance'] = pednet.geom.length\n",
    "pednet['distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating network graph\n",
    "G = create_graph(pednet)\n",
    "#from G to urbanaccess network model - one node idx,x,y one edge from to weight\n",
    "#G.edges(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#degree calculation\n",
    "degrees = [val for (node, val) in G.degree()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##G centrality calculation\n",
    "import time\n",
    "start = time.time()\n",
    "deg_centrality = nx.degree_centrality(G)\n",
    "a_list = []\n",
    "b_list = []\n",
    "for node, val in sorted(deg_centrality.items(), key=lambda x: x[1],  reverse=True):\n",
    "     a_list.append(node)\n",
    "     b_list.append(val)\n",
    "     df = pd.DataFrame({'Node': a_list, 'Degree': b_list})\n",
    "del a_list, b_list\n",
    "    #print(node, val)\n",
    "end = time.time()\n",
    "df.to_csv(\"./deg_centrality.csv\")\n",
    "print(end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#closeness_centrality 19160.19558262825\n",
    "import time\n",
    "start = time.time()\n",
    "closeness_centrality = nx.closeness_centrality(G)\n",
    "a_list = []\n",
    "b_list = []\n",
    "for node, val in sorted(closeness_centrality.items(), key=lambda x: x[1],  reverse=True):\n",
    "     a_list.append(node)\n",
    "     b_list.append(val)\n",
    "     df1 = pd.DataFrame({'Node': a_list, 'closeness_centrality': b_list})\n",
    "\n",
    "    \n",
    "del a_list, b_list\n",
    "    #print(node, val)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#betweenness_centrality\n",
    "import time\n",
    "start = time.time()\n",
    "betweenness_centrality = nx.betweenness_centrality(G)\n",
    "a_list = []\n",
    "b_list = []\n",
    "for node, val in sorted(betweenness_centrality.items(), key=lambda x: x[1],  reverse=True):\n",
    "     a_list.append(node)\n",
    "     b_list.append(val)\n",
    "     df2 = pd.DataFrame({'Node': a_list, 'betweenness_centrality': b_list})\n",
    "\n",
    "    \n",
    "del a_list, b_list\n",
    "    #print(node, val)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "df1.to_csv(\"./closeness_centrality.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiprocessing betweenness if necessary\n",
    "from multiprocessing import Pool\n",
    "import itertools\n",
    "def partitions(nodes, n):\n",
    "    \"Partitions the nodes into n subsets\"\n",
    "    nodes_iter = iter(nodes)\n",
    "    while True:\n",
    "        partition = tuple(itertools.islice(nodes_iter,n))\n",
    "        if not partition:\n",
    "            return\n",
    "        yield partition\n",
    "def between_parallel(G, processes = None):\n",
    "    p = Pool(processes=processes)\n",
    "    part_generator = 4*len(p._pool)\n",
    "    node_partitions = list(partitions(G.nodes(), int(len(G)/part_generator)))\n",
    "    num_partitions = len(node_partitions)\n",
    " \n",
    "    bet_map = p.map(btwn_pool,\n",
    "                        zip([G]*num_partitions,\n",
    "                        [True]*num_partitions,\n",
    "                        [None]*num_partitions,\n",
    "                        node_partitions))\n",
    " \n",
    "    bt_c = bet_map[0]\n",
    "    for bt in bet_map[1:]:\n",
    "        for n in bt:\n",
    "            bt_c[n] += bt[n]\n",
    "    return bt_c\n",
    "bt = between_parallel(G)\n",
    "#bt.to_csv(\"./betweenness.csv\")\n",
    "betweenness= pd.DataFrame.from_dict(bt, orient='index').to_csv(\"./betweenness1.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get network \"from\" and \"to\" from nodes\n",
    "edges = nx.to_pandas_edgelist(G,'from','to')\n",
    "to = edges['to'].tolist()\n",
    "fr = edges['from'].tolist()\n",
    "fr = list(set(fr))\n",
    "to = list(set(to))\n",
    "to.extend(fr)\n",
    "nodes = list(set(to))\n",
    "nodes = pd.DataFrame(nodes)\n",
    "nodes.columns=['x', 'y']\n",
    "nodes['xy'] = nodes.apply(lambda z: (z.x,z.y),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save nodes\n",
    "nodes.to_csv(\"./nodes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi processing network nodes and edges index creation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "start = time.time()\n",
    "num_partitions = 16 #number of partitions to split dataframe\n",
    "num_cores = 16 #number of cores on your machine\n",
    "\n",
    "\n",
    "\n",
    "def parallelize_dataframe(df, func):\n",
    "    df_split = np.array_split(df, num_partitions)\n",
    "    pool = Pool(num_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df\n",
    "\n",
    "def set_node_id(edges):\n",
    "    nodes = pd.read_csv('./nodes.csv')\n",
    "    edges = pd.read_csv('./edges.csv')\n",
    "    for ix, node in nodes.iterrows():\n",
    "        indicies = edges[edges.to == node.xy].index\n",
    "        edges.loc[indicies,'to'] = ix\n",
    "        indicies = edges[edges['from'] == node.xy].index\n",
    "        edges.loc[indicies,'from'] = ix\n",
    "    return edges\n",
    "    \n",
    "    \n",
    "edges = parallelize_dataframe(edges, set_node_id)\n",
    "end = time.time()\n",
    "print(end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the Pandana network \n",
    "#https://github.com/gboeing/urban-data-science/blob/master/20-Accessibility-Walkability/pandana-accessibility-demo-simple.ipynb\n",
    "# if there is an error, please run this before creating pdna network\n",
    "edges[\"to\"] = edges[\"to\"].astype(int)\n",
    "edges[\"from\"] = edges[\"from\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating pandana network\n",
    "import pandana as pdna\n",
    "import pandas as pd\n",
    "from pandana import Network\n",
    "\n",
    "transit_ped_net = pdna.Network(nodes[\"x\"],\n",
    "                               nodes[\"y\"],\n",
    "                               edges[\"from\"],\n",
    "                               edges[\"to\"],\n",
    "                               pd.DataFrame([edges1.length]).T,\n",
    "                               twoway=True)\n",
    "\n",
    "transit_ped_net.save_hdf5('/media/DATADRIVE/walkability/ped_net_final_0525.hd5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "transit_ped_net.precompute(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the network from saved file\n",
    "transit_ped_net = pdna.Network.from_hdf5('/media/DATADRIVE/walkability/ped_net_final_0525.hd5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from pg database total 23 layers\n",
    "con = psycopg2.connect(database=\"walkability\", user=\"postgres\", password=****,\n",
    "    host=\"****\",port=\"5432\")\n",
    "#service layers\n",
    "foodconv = gpd.read_postgis('SELECT * FROM staging.food_convenience_store',con,crs={'init': 'epsg:2019'})\n",
    "fastfood = gpd.read_postgis('SELECT * FROM staging.food_fastfood',con,crs={'init': 'epsg:2019'})\n",
    "supermarket = gpd.read_postgis('SELECT * FROM staging.food_supermarket',con,crs={'init': 'epsg:2019'})\n",
    "hospital = gpd.read_postgis('SELECT * FROM staging.health_hospital',con,crs={'init': 'epsg:2019'})\n",
    "sxhclinic = gpd.read_postgis('SELECT * FROM staging.health_sexual_health_clinic',con,crs={'init': 'epsg:2019'})\n",
    "wkclinic = gpd.read_postgis('SELECT * FROM staging.health_walkin',con,crs={'init': 'epsg:2019'})\n",
    "arena = gpd.read_postgis('SELECT * FROM staging.publicservice_arena',con,crs={'init': 'epsg:2019'})\n",
    "daycare = gpd.read_postgis('SELECT * FROM staging.publicservice_day_care_centre',con,crs={'init': 'epsg:2019'})\n",
    "dropin = gpd.read_postgis('SELECT * FROM staging.publicservice_dropin',con,crs={'init': 'epsg:2019'})\n",
    "ems = gpd.read_postgis('SELECT * FROM staging.publicservice_ems',con,crs={'init': 'epsg:2019'})\n",
    "famcentre = gpd.read_postgis('SELECT * FROM staging.publicservice_family_resource_centre',con,crs={'init': 'epsg:2019'})\n",
    "fire = gpd.read_postgis('SELECT * FROM staging.publicservice_fire_facility',con,crs={'init': 'epsg:2019'})\n",
    "library = gpd.read_postgis('SELECT * FROM staging.publicservice_library',con,crs={'init': 'epsg:2019'})\n",
    "police = gpd.read_postgis('SELECT * FROM staging.publicservice_police_facility',con,crs={'init': 'epsg:2019'})\n",
    "recreation = gpd.read_postgis('SELECT * FROM staging.publicservice_recreation',con,crs={'init': 'epsg:2019'})\n",
    "school = gpd.read_postgis('SELECT * FROM staging.publicservice_school',con,crs={'init': 'epsg:2019'})\n",
    "thingstodo = gpd.read_postgis('SELECT * FROM staging.publicservice_thingstodo',con,crs={'init': 'epsg:2019'})\n",
    "voteloc = gpd.read_postgis('SELECT * FROM staging.publicservice_voting_location',con,crs={'init': 'epsg:2019'})\n",
    "bike_parking = gpd.read_postgis('SELECT * FROM staging.transit_bicycle_parking_on_street',con,crs={'init': 'epsg:2019'})\n",
    "bike_station = gpd.read_postgis('SELECT * FROM staging.transit_bicycle_station_indoor',con,crs={'init': 'epsg:2019'})\n",
    "ttc_station = gpd.read_postgis('SELECT * FROM staging.transit_ttc_station',con,crs={'init': 'epsg:2019'})\n",
    "ttc_accessible = gpd.read_postgis('SELECT * FROM staging.transit_ttc_station_accessible',con,crs={'init': 'epsg:2019'})\n",
    "ttc_stop = gpd.read_postgis('SELECT * FROM staging.transit_ttc_stop',con,crs={'init': 'epsg:2019'})\n",
    "ts = gpd.read_postgis('SELECT * FROM staging.traffic_signals',con,crs={'init': 'epsg:2019'})\n",
    "buildings = gpd.read_postgis('SELECT * FROM public.buildings_blank',con,crs={'init': 'epsg:2019'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep wanted columns\n",
    "foodconv=foodconv[['gid', 'x', 'y','name','type']]\n",
    "fastfood=fastfood[['gid', 'x', 'y','name','type']]\n",
    "supermarket=supermarket[['gid', 'x', 'y','name','type']]\n",
    "hospital=hospital[['gid', 'x', 'y','name','type']]\n",
    "sxhclinic=sxhclinic[['gid', 'x', 'y','name','ward']]\n",
    "wkclinic=wkclinic[['gid', 'x', 'y','name','type']]\n",
    "school=school[['gid', 'x', 'y','name','school_type']]\n",
    "arena=arena[['gid', 'x', 'y','name','community']]\n",
    "daycare=daycare[['gid', 'x', 'y','name','place_name']]\n",
    "dropin=dropin[['gid', 'x', 'y','name','facility']]\n",
    "ems=ems[['gid', 'x', 'y','name','place_name']]\n",
    "famcentre=famcentre[['gid', 'x', 'y','name','agency']]\n",
    "fire=fire[['gid', 'x', 'y','name','address']]\n",
    "library=library[['gid', 'x', 'y','name','address_full']]\n",
    "police=police[['gid', 'x', 'y','name','address']]\n",
    "recreation=recreation[['gid', 'x', 'y','rc_name','rc_type']]\n",
    "thingstodo=thingstodo[['gid', 'x', 'y','name','td_type']]\n",
    "voteloc=voteloc[['gid', 'x', 'y','name','linear_nam']]\n",
    "bike_parking=bike_parking[['gid', 'x', 'y','address_fu','parking_ty']]\n",
    "bike_station=bike_station[['gid', 'x', 'y','address_fu','station_ty']]\n",
    "ttc_station=ttc_station[['gid', 'x', 'y','name','pt_type']]\n",
    "ttc_stop=ttc_stop[['gid', 'x', 'y','name','stop_code']]\n",
    "ttc_accessible=ttc_accessible[['gid', 'x', 'y','name','pt_type']]\n",
    "ts=ts[['gid', 'x', 'y','main','side_1']]\n",
    "buildings= buildings[['ctuid', 'ctname', 'ctnum', 'geotext', 'geom', 'gid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/pandana/network.py:370: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  distances, indexes = self.kdtree.query(xys.as_matrix())\n"
     ]
    }
   ],
   "source": [
    "#get node_ids for points for each layer\n",
    "\n",
    "x, y = foodconv.x, foodconv.y\n",
    "foodconv[\"node_ids\"] = transit_ped_net.get_node_ids(x, y)\n",
    "transit_ped_net.set(foodconv[\"node_ids\"], name=\"foodconv\")\n",
    "\n",
    "x, y = fastfood.x, fastfood.y\n",
    "fastfood[\"node_ids\"] = transit_ped_net.get_node_ids(x, y)\n",
    "transit_ped_net.set(fastfood[\"node_ids\"], name=\"fastfood\")\n",
    "\n",
    "#supermarket\n",
    "x, y = supermarket.x, supermarket.y\n",
    "supermarket[\"node_ids\"] = transit_ped_net.get_node_ids(x, y)\n",
    "transit_ped_net.set(supermarket[\"node_ids\"], name=\"supermarket\")\n",
    "\n",
    "x, y = hospital.x, hospital.y\n",
    "hospital[\"node_ids\"] = transit_ped_net.get_node_ids(x, y)\n",
    "transit_ped_net.set(hospital[\"node_ids\"], name=\"hospital\")\n",
    "\n",
    "x, y = sxhclinic.x, sxhclinic.y\n",
    "sxhclinic[\"node_ids\"] = transit_ped_net.get_node_ids(x, y)\n",
    "transit_ped_net.set(sxhclinic[\"node_ids\"], name=\"sxhclinic\")\n",
    "\n",
    "x, y = wkclinic.x, wkclinic.y\n",
    "wkclinic[\"node_ids\"] = transit_ped_net.get_node_ids(x, y)\n",
    "transit_ped_net.set(wkclinic[\"node_ids\"], name=\"wkclinic\")\n",
    "\n",
    "x, y = school.x, school.y\n",
    "school[\"node_ids\"] = transit_ped_net.get_node_ids(x, y)\n",
    "transit_ped_net.set(school[\"node_ids\"], name=\"school\")\n",
    "\n",
    "x, y = arena.x, arena.y\n",
    "arena[\"node_ids\"] = transit_ped_net.get_node_ids(x, y)\n",
    "transit_ped_net.set(arena[\"node_ids\"], name=\"arena\")\n",
    "\n",
    "x, y = daycare.x, daycare.y\n",
    "daycare[\"node_ids\"] = transit_ped_net.get_node_ids(x, y)\n",
    "transit_ped_net.set(daycare[\"node_ids\"], name=\"daycare\")\n",
    "\n",
    "x, y = dropin.x, dropin.y\n",
    "dropin[\"node_ids\"] = transit_ped_net.get_node_ids(x, y)\n",
    "transit_ped_net.set(dropin[\"node_ids\"], name=\"dropin\")\n",
    "\n",
    "x, y = ems.x, ems.y\n",
    "ems[\"node_ids\"] = transit_ped_net.get_node_ids(x, y)\n",
    "transit_ped_net.set(ems[\"node_ids\"], name=\"ems\")\n",
    "\n",
    "x, y = famcentre.x, famcentre.y\n",
    "famcentre[\"node_ids\"] = transit_ped_net.get_node_ids(x, y)\n",
    "transit_ped_net.set(famcentre[\"node_ids\"], name=\"famcentre\")\n",
    "\n",
    "x, y = fire.x, fire.y\n",
    "fire[\"node_ids\"] = transit_ped_net.get_node_ids(x, y)\n",
    "transit_ped_net.set(fire[\"node_ids\"], name=\"fire\")\n",
    "\n",
    "x, y = library.x, library.y\n",
    "library[\"node_ids\"] = transit_ped_net.get_node_ids(x, y)\n",
    "transit_ped_net.set(library[\"node_ids\"], name=\"library\")\n",
    "\n",
    "x, y = police.x, police.y\n",
    "police[\"node_ids\"] = transit_ped_net.get_node_ids(x, y)\n",
    "transit_ped_net.set(police[\"node_ids\"], name=\"police\")\n",
    "\n",
    "x, y = recreation.x, recreation.y\n",
    "recreation[\"node_ids\"] = transit_ped_net.get_node_ids(x, y)\n",
    "transit_ped_net.set(recreation[\"node_ids\"], name=\"recreation\")\n",
    "\n",
    "x, y = thingstodo.x, thingstodo.y\n",
    "thingstodo[\"node_ids\"] = transit_ped_net.get_node_ids(x, y)\n",
    "transit_ped_net.set(thingstodo[\"node_ids\"], name=\"thingstodo\")\n",
    "\n",
    "x, y = voteloc.x, voteloc.y\n",
    "voteloc[\"node_ids\"] = transit_ped_net.get_node_ids(x, y)\n",
    "transit_ped_net.set(voteloc[\"node_ids\"], name=\"voteloc\")\n",
    "\n",
    "x, y = bike_parking.x, bike_parking.y\n",
    "bike_parking[\"node_ids\"] = transit_ped_net.get_node_ids(x, y)\n",
    "transit_ped_net.set(bike_parking[\"node_ids\"], name=\"bike_parking\")\n",
    "\n",
    "x, y = bike_station.x, bike_station.y\n",
    "bike_station[\"node_ids\"] = transit_ped_net.get_node_ids(x, y)\n",
    "transit_ped_net.set(bike_station[\"node_ids\"], name=\"bike_station\")\n",
    "\n",
    "x, y = ttc_stop.x, ttc_stop.y\n",
    "ttc_stop[\"node_ids\"] = transit_ped_net.get_node_ids(x, y)\n",
    "transit_ped_net.set(ttc_stop[\"node_ids\"], name=\"ttc_stop\")\n",
    "\n",
    "x, y = ttc_station.x, ttc_station.y\n",
    "ttc_station[\"node_ids\"] = transit_ped_net.get_node_ids(x, y)\n",
    "transit_ped_net.set(ttc_station[\"node_ids\"], name=\"ttc_station\")\n",
    "\n",
    "x, y = ttc_accessible.x, ttc_accessible.y\n",
    "ttc_accessible[\"node_ids\"] = transit_ped_net.get_node_ids(x, y)\n",
    "transit_ped_net.set(ttc_accessible[\"node_ids\"], name=\"ttc_accessible\")\n",
    "\n",
    "x, y = ts.x, ts.y\n",
    "ts[\"node_ids\"] = transit_ped_net.get_node_ids(x, y)\n",
    "transit_ped_net.set(ts[\"node_ids\"], name=\"ts\")\n",
    "\n",
    "x, y = buildings.geom.centroid.x, buildings.geom.centroid.y\n",
    "buildings[\"node_ids\"] = transit_ped_net.get_node_ids(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get nearest 2 points with id\n",
    "n=2\n",
    "maxdistance = 5000 \n",
    "\n",
    "transit_ped_net.set_pois(\"foodconv\", maxdistance , n, foodconv.x, foodconv.y)\n",
    "foodconv_walk_distances = transit_ped_net.nearest_pois(maxdistance , \"foodconv\", num_pois=n, include_poi_ids=True)\n",
    "\n",
    "transit_ped_net.set_pois(\"fastfood\", maxdistance , n, fastfood.x, fastfood.y)\n",
    "fastfood_walk_distances = transit_ped_net.nearest_pois(maxdistance , \"fastfood\", num_pois=n, include_poi_ids=True)\n",
    "\n",
    "transit_ped_net.set_pois(\"supermarket\", maxdistance , n, supermarket.x, supermarket.y)\n",
    "supermarket_walk_distances = transit_ped_net.nearest_pois(maxdistance , \"supermarket\", num_pois=n, include_poi_ids=True)\n",
    "\n",
    "transit_ped_net.set_pois(\"hospital\", maxdistance , n, hospital.x, hospital.y)\n",
    "hospital_walk_distances = transit_ped_net.nearest_pois(maxdistance , \"hospital\", num_pois=n, include_poi_ids=True)\n",
    "\n",
    "transit_ped_net.set_pois(\"sxhclinic\", maxdistance , n, sxhclinic.x, sxhclinic.y)\n",
    "sxhclinic_walk_distances = transit_ped_net.nearest_pois(maxdistance , \"sxhclinic\", num_pois=n, include_poi_ids=True)\n",
    "\n",
    "transit_ped_net.set_pois(\"wkclinic\", maxdistance , n, wkclinic.x, wkclinic.y)\n",
    "wkclinic_walk_distances = transit_ped_net.nearest_pois(maxdistance , \"wkclinic\", num_pois=n, include_poi_ids=True)\n",
    "\n",
    "\n",
    "transit_ped_net.set_pois(\"school\", maxdistance , n, school.x, school.y)\n",
    "school_walk_distances = transit_ped_net.nearest_pois(maxdistance , \"school\", num_pois=n, include_poi_ids=True)\n",
    "\n",
    "transit_ped_net.set_pois(\"arena\", maxdistance , n, arena.x, arena.y)\n",
    "arena_walk_distances = transit_ped_net.nearest_pois(maxdistance , \"arena\", num_pois=n, include_poi_ids=True)\n",
    "\n",
    "transit_ped_net.set_pois(\"daycare\", maxdistance , n, daycare.x, daycare.y)\n",
    "daycare_walk_distances = transit_ped_net.nearest_pois(maxdistance , \"daycare\", num_pois=n, include_poi_ids=True)\n",
    "\n",
    "transit_ped_net.set_pois(\"dropin\", maxdistance , n, dropin.x, dropin.y)\n",
    "dropin_walk_distances = transit_ped_net.nearest_pois(maxdistance , \"dropin\", num_pois=n, include_poi_ids=True)\n",
    "\n",
    "transit_ped_net.set_pois(\"ems\", maxdistance , n, ems.x, ems.y)\n",
    "ems_walk_distances = transit_ped_net.nearest_pois(maxdistance , \"ems\", num_pois=n, include_poi_ids=True)\n",
    "\n",
    "transit_ped_net.set_pois(\"famcentre\", maxdistance , n, famcentre.x, famcentre.y)\n",
    "famcentre_walk_distances = transit_ped_net.nearest_pois(maxdistance , \"famcentre\", num_pois=n, include_poi_ids=True)\n",
    "\n",
    "transit_ped_net.set_pois(\"fire\", maxdistance , n, fire.x, fire.y)\n",
    "fire_walk_distances = transit_ped_net.nearest_pois(maxdistance , \"fire\", num_pois=n, include_poi_ids=True)\n",
    "\n",
    "transit_ped_net.set_pois(\"library\", maxdistance , n, library.x, library.y)\n",
    "library_walk_distances = transit_ped_net.nearest_pois(maxdistance , \"library\", num_pois=n, include_poi_ids=True)\n",
    "\n",
    "transit_ped_net.set_pois(\"police\", maxdistance , n, police.x, police.y)\n",
    "police_walk_distances = transit_ped_net.nearest_pois(maxdistance , \"police\", num_pois=n, include_poi_ids=True)\n",
    "\n",
    "transit_ped_net.set_pois(\"recreation\", maxdistance , n, recreation.x, recreation.y)\n",
    "recreation_walk_distances = transit_ped_net.nearest_pois(maxdistance , \"recreation\", num_pois=n, include_poi_ids=True)\n",
    "\n",
    "transit_ped_net.set_pois(\"thingstodo\", maxdistance , n, thingstodo.x, thingstodo.y)\n",
    "thingstodo_walk_distances = transit_ped_net.nearest_pois(maxdistance , \"thingstodo\", num_pois=n, include_poi_ids=True)\n",
    "\n",
    "transit_ped_net.set_pois(\"voteloc\", maxdistance , n, voteloc.x, voteloc.y)\n",
    "voteloc_walk_distances = transit_ped_net.nearest_pois(maxdistance , \"voteloc\", num_pois=n, include_poi_ids=True)\n",
    "\n",
    "transit_ped_net.set_pois(\"bike_parking\", maxdistance , n, bike_parking.x, bike_parking.y)\n",
    "bike_parking_walk_distances = transit_ped_net.nearest_pois(maxdistance , \"bike_parking\", num_pois=n, include_poi_ids=True)\n",
    "\n",
    "transit_ped_net.set_pois(\"bike_station\", maxdistance , n, bike_station.x, bike_station.y)\n",
    "bike_station_walk_distances = transit_ped_net.nearest_pois(maxdistance , \"bike_station\", num_pois=n, include_poi_ids=True)\n",
    "\n",
    "transit_ped_net.set_pois(\"ttc_stop\", maxdistance , n, ttc_stop.x, ttc_stop.y)\n",
    "ttc_stop_walk_distances = transit_ped_net.nearest_pois(maxdistance , \"ttc_stop\", num_pois=n, include_poi_ids=True)\n",
    "\n",
    "transit_ped_net.set_pois(\"ttc_station\", maxdistance , n, ttc_station.x, ttc_station.y)\n",
    "ttc_station_walk_distances = transit_ped_net.nearest_pois(maxdistance , \"ttc_station\", num_pois=n, include_poi_ids=True)\n",
    "\n",
    "transit_ped_net.set_pois(\"ttc_accessible\", maxdistance , n, ttc_accessible.x, ttc_accessible.y)\n",
    "ttc_accessible_walk_distances = transit_ped_net.nearest_pois(maxdistance , \"ttc_accessible\", num_pois=n, include_poi_ids=True)\n",
    "\n",
    "transit_ped_net.set_pois(\"ts\", maxdistance , n, ts.x, ts.y)\n",
    "ts_walk_distances = transit_ped_net.nearest_pois(maxdistance , \"ts\", num_pois=n, include_poi_ids=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep wanted columns\n",
    "foodconv.drop(['x', 'y', 'node_ids'], axis=1, inplace=True)\n",
    "fastfood.drop(['x', 'y', 'node_ids'], axis=1, inplace=True)\n",
    "supermarket.drop(['x', 'y', 'node_ids'], axis=1, inplace=True)\n",
    "hospital.drop(['x', 'y', 'node_ids'], axis=1, inplace=True)\n",
    "sxhclinic.drop(['x', 'y', 'node_ids'], axis=1, inplace=True)\n",
    "wkclinic.drop(['x', 'y', 'node_ids'], axis=1, inplace=True)\n",
    "school.drop(['x', 'y', 'node_ids'], axis=1, inplace=True)\n",
    "arena.drop(['x', 'y', 'node_ids'], axis=1, inplace=True)\n",
    "daycare.drop(['x', 'y', 'node_ids'], axis=1, inplace=True)\n",
    "dropin.drop(['x', 'y', 'node_ids'], axis=1, inplace=True)\n",
    "ems.drop(['x', 'y', 'node_ids'], axis=1, inplace=True)\n",
    "famcentre.drop(['x', 'y', 'node_ids'], axis=1, inplace=True)\n",
    "fire.drop(['x', 'y', 'node_ids'], axis=1, inplace=True)\n",
    "library.drop(['x', 'y', 'node_ids'], axis=1, inplace=True)\n",
    "police.drop(['x', 'y', 'node_ids'], axis=1, inplace=True)\n",
    "recreation.drop(['x', 'y', 'node_ids'], axis=1, inplace=True)\n",
    "thingstodo.drop(['x', 'y', 'node_ids'], axis=1, inplace=True)\n",
    "voteloc.drop(['x', 'y', 'node_ids'], axis=1, inplace=True)\n",
    "bike_parking.drop(['x', 'y', 'node_ids'], axis=1, inplace=True)\n",
    "bike_station.drop(['x', 'y', 'node_ids'], axis=1, inplace=True)\n",
    "ttc_station.drop(['x', 'y', 'node_ids'], axis=1, inplace=True)\n",
    "ttc_stop.drop(['x', 'y', 'node_ids'], axis=1, inplace=True)\n",
    "ttc_accessible.drop(['x', 'y', 'node_ids'], axis=1, inplace=True)\n",
    "ts.drop(['x', 'y', 'node_ids'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "n=2\n",
    "columns =  ['d_fc_'+str(i) for i in range(0,n,1)]\n",
    "columns.extend(['n_fc_'+str(i) for i in range(0,n,1)])\n",
    "foodconv_walk_distances.columns = columns\n",
    "\n",
    "columns =  ['d_ff_'+str(i) for i in range(0,n,1)]\n",
    "columns.extend(['n_ff_'+str(i) for i in range(0,n,1)])\n",
    "fastfood_walk_distances.columns = columns\n",
    "\n",
    "columns =  ['d_sm_'+str(i) for i in range(0,n,1)]\n",
    "columns.extend(['n_sm_'+str(i) for i in range(0,n,1)])\n",
    "supermarket_walk_distances.columns = columns\n",
    "\n",
    "columns =  ['d_hp_'+str(i) for i in range(0,n,1)]\n",
    "columns.extend(['n_hp_'+str(i) for i in range(0,n,1)])\n",
    "hospital_walk_distances.columns = columns\n",
    "\n",
    "columns =  ['d_sxhc_'+str(i) for i in range(0,n,1)]\n",
    "columns.extend(['n_sxhc_'+str(i) for i in range(0,n,1)])\n",
    "sxhclinic_walk_distances.columns = columns\n",
    "\n",
    "columns =  ['d_wc_'+str(i) for i in range(0,n,1)]\n",
    "columns.extend(['n_wc_'+str(i) for i in range(0,n,1)])\n",
    "wkclinic_walk_distances.columns = columns\n",
    "\n",
    "columns =  ['d_sc_'+str(i) for i in range(0,n,1)]\n",
    "columns.extend(['n_sc_'+str(i) for i in range(0,n,1)])\n",
    "school_walk_distances.columns = columns\n",
    "\n",
    "columns =  ['d_ar_'+str(i) for i in range(0,n,1)]\n",
    "columns.extend(['n_ar_'+str(i) for i in range(0,n,1)])\n",
    "arena_walk_distances.columns = columns\n",
    "\n",
    "columns =  ['d_dc_'+str(i) for i in range(0,n,1)]\n",
    "columns.extend(['n_dc_'+str(i) for i in range(0,n,1)])\n",
    "daycare_walk_distances.columns = columns\n",
    "\n",
    "columns =  ['d_di_'+str(i) for i in range(0,n,1)]\n",
    "columns.extend(['n_di_'+str(i) for i in range(0,n,1)])\n",
    "dropin_walk_distances.columns = columns\n",
    "\n",
    "columns =  ['d_ems_'+str(i) for i in range(0,n,1)]\n",
    "columns.extend(['n_ems_'+str(i) for i in range(0,n,1)])\n",
    "ems_walk_distances.columns = columns\n",
    "\n",
    "columns =  ['d_frc_'+str(i) for i in range(0,n,1)]\n",
    "columns.extend(['n_frc_'+str(i) for i in range(0,n,1)])\n",
    "famcentre_walk_distances.columns = columns\n",
    "\n",
    "columns =  ['d_fr_'+str(i) for i in range(0,n,1)]\n",
    "columns.extend(['n_fr_'+str(i) for i in range(0,n,1)])\n",
    "fire_walk_distances.columns = columns\n",
    "\n",
    "columns =  ['d_lb_'+str(i) for i in range(0,n,1)]\n",
    "columns.extend(['n_lb_'+str(i) for i in range(0,n,1)])\n",
    "library_walk_distances.columns = columns\n",
    "\n",
    "columns =  ['d_plc_'+str(i) for i in range(0,n,1)]\n",
    "columns.extend(['n_plc_'+str(i) for i in range(0,n,1)])\n",
    "police_walk_distances.columns = columns\n",
    "\n",
    "columns =  ['d_rec_'+str(i) for i in range(0,n,1)]\n",
    "columns.extend(['n_rec_'+str(i) for i in range(0,n,1)])\n",
    "recreation_walk_distances.columns = columns\n",
    "\n",
    "columns =  ['d_thing_'+str(i) for i in range(0,n,1)]\n",
    "columns.extend(['n_thing_'+str(i) for i in range(0,n,1)])\n",
    "thingstodo_walk_distances.columns = columns\n",
    "\n",
    "columns =  ['d_vtl_'+str(i) for i in range(0,n,1)]\n",
    "columns.extend(['n_vtl_'+str(i) for i in range(0,n,1)])\n",
    "voteloc_walk_distances.columns = columns\n",
    "\n",
    "columns =  ['d_bp_'+str(i) for i in range(0,n,1)]\n",
    "columns.extend(['n_bp_'+str(i) for i in range(0,n,1)])\n",
    "bike_parking_walk_distances.columns = columns\n",
    "\n",
    "columns =  ['d_bs_'+str(i) for i in range(0,n,1)]\n",
    "columns.extend(['n_bs_'+str(i) for i in range(0,n,1)])\n",
    "bike_station_walk_distances.columns = columns\n",
    "\n",
    "columns =  ['d_ttcstop_'+str(i) for i in range(0,n,1)]\n",
    "columns.extend(['n_ttcstop_'+str(i) for i in range(0,n,1)])\n",
    "ttc_stop_walk_distances.columns = columns\n",
    "\n",
    "columns =  ['d_ttcst_'+str(i) for i in range(0,n,1)]\n",
    "columns.extend(['n_ttcst_'+str(i) for i in range(0,n,1)])\n",
    "ttc_station_walk_distances.columns = columns\n",
    "\n",
    "columns =  ['d_ttcacc_'+str(i) for i in range(0,n,1)]\n",
    "columns.extend(['n_ttcacc_'+str(i) for i in range(0,n,1)])\n",
    "ttc_accessible_walk_distances.columns = columns\n",
    "\n",
    "columns =  ['d_ts_'+str(i) for i in range(0,n,1)]\n",
    "columns.extend(['n_ts_'+str(i) for i in range(0,n,1)])\n",
    "ts_walk_distances.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging walk distances with buildings data\n",
    "c = 0\n",
    "l = len(buildings.node_ids.unique())\n",
    "for ix,group in buildings.groupby('node_ids'):\n",
    "    group\n",
    "    c +=1\n",
    "\n",
    "    for j in range(0,n,1):\n",
    "        \n",
    "        buildings.loc[group.index,'d_fc_{}'.format(j)] = foodconv_walk_distances.loc[ix]['d_fc_{}'.format(j)]\n",
    "        buildings.loc[group.index,'n_fc_{}'.format(j)] =foodconv_walk_distances.loc[ix]['n_fc_{}'.format(j)]\n",
    "        \n",
    "        buildings.loc[group.index,'d_ff_{}'.format(j)] = fastfood_walk_distances.loc[ix]['d_ff_{}'.format(j)]\n",
    "        buildings.loc[group.index,'n_ff_{}'.format(j)] = fastfood_walk_distances.loc[ix]['n_ff_{}'.format(j)] \n",
    "      \n",
    "        buildings.loc[group.index,'d_sm_{}'.format(j)] = supermarket_walk_distances.loc[ix]['d_sm_{}'.format(j)]\n",
    "        buildings.loc[group.index,'n_sm_{}'.format(j)] = supermarket_walk_distances.loc[ix]['n_sm_{}'.format(j)]\n",
    "        \n",
    "        buildings.loc[group.index,'d_hp_{}'.format(j)] = hospital_walk_distances.loc[ix]['d_hp_{}'.format(j)]\n",
    "        buildings.loc[group.index,'n_hp_{}'.format(j)] = hospital_walk_distances.loc[ix]['n_hp_{}'.format(j)]\n",
    "        \n",
    "        buildings.loc[group.index,'d_sxhc_{}'.format(j)] = sxhclinic_walk_distances.loc[ix]['d_sxhc_{}'.format(j)]\n",
    "        buildings.loc[group.index,'n_sxhc_{}'.format(j)] = sxhclinic_walk_distances.loc[ix]['n_sxhc_{}'.format(j)]\n",
    "        \n",
    "        buildings.loc[group.index,'d_wc_{}'.format(j)] = wkclinic_walk_distances.loc[ix]['d_wc_{}'.format(j)]\n",
    "        buildings.loc[group.index,'n_wc_{}'.format(j)] = wkclinic_walk_distances.loc[ix]['n_wc_{}'.format(j)]\n",
    "        \n",
    "        buildings.loc[group.index,'d_sc_{}'.format(j)] = school_walk_distances.loc[ix]['d_sc_{}'.format(j)]\n",
    "        buildings.loc[group.index,'n_sc_{}'.format(j)] = school_walk_distances.loc[ix]['n_sc_{}'.format(j)]\n",
    "        \n",
    "        buildings.loc[group.index,'d_ar_{}'.format(j)] = arena_walk_distances.loc[ix]['d_ar_{}'.format(j)]\n",
    "        buildings.loc[group.index,'n_ar_{}'.format(j)] = arena_walk_distances.loc[ix]['n_ar_{}'.format(j)]\n",
    "        \n",
    "        buildings.loc[group.index,'d_dc_{}'.format(j)] = daycare_walk_distances.loc[ix]['d_dc_{}'.format(j)]\n",
    "        buildings.loc[group.index,'n_dc_{}'.format(j)] = daycare_walk_distances.loc[ix]['n_dc_{}'.format(j)]\n",
    "        \n",
    "        buildings.loc[group.index,'d_di_{}'.format(j)] = dropin_walk_distances.loc[ix]['d_di_{}'.format(j)]\n",
    "        buildings.loc[group.index,'n_di_{}'.format(j)] = dropin_walk_distances.loc[ix]['n_di_{}'.format(j)]\n",
    "        \n",
    "        buildings.loc[group.index,'d_ems_{}'.format(j)] = ems_walk_distances.loc[ix]['d_ems_{}'.format(j)]\n",
    "        buildings.loc[group.index,'n_ems_{}'.format(j)] = ems_walk_distances.loc[ix]['n_ems_{}'.format(j)]\n",
    "        \n",
    "        buildings.loc[group.index,'d_frc_{}'.format(j)] = famcentre_walk_distances.loc[ix]['d_frc_{}'.format(j)]\n",
    "        buildings.loc[group.index,'n_frc_{}'.format(j)] = famcentre_walk_distances.loc[ix]['n_frc_{}'.format(j)]\n",
    "        \n",
    "        buildings.loc[group.index,'d_fr_{}'.format(j)] = fire_walk_distances.loc[ix]['d_fr_{}'.format(j)]\n",
    "        buildings.loc[group.index,'n_fr_{}'.format(j)] = fire_walk_distances.loc[ix]['n_fr_{}'.format(j)]\n",
    "        \n",
    "        buildings.loc[group.index,'d_lb_{}'.format(j)] = library_walk_distances.loc[ix]['d_lb_{}'.format(j)]\n",
    "        buildings.loc[group.index,'n_lb_{}'.format(j)] = library_walk_distances.loc[ix]['n_lb_{}'.format(j)]\n",
    "        \n",
    "        buildings.loc[group.index,'d_plc_{}'.format(j)] = police_walk_distances.loc[ix]['d_plc_{}'.format(j)]\n",
    "        buildings.loc[group.index,'n_plc_{}'.format(j)] = police_walk_distances.loc[ix]['n_plc_{}'.format(j)]\n",
    "        \n",
    "        buildings.loc[group.index,'d_rec_{}'.format(j)] = recreation_walk_distances.loc[ix]['d_rec_{}'.format(j)]\n",
    "        buildings.loc[group.index,'n_rec_{}'.format(j)] = recreation_walk_distances.loc[ix]['n_rec_{}'.format(j)]\n",
    "        \n",
    "        buildings.loc[group.index,'d_thing_{}'.format(j)] = thingstodo_walk_distances.loc[ix]['d_thing_{}'.format(j)]\n",
    "        buildings.loc[group.index,'n_thing_{}'.format(j)] = thingstodo_walk_distances.loc[ix]['n_thing_{}'.format(j)]\n",
    "        \n",
    "        buildings.loc[group.index,'d_vtl_{}'.format(j)] = voteloc_walk_distances.loc[ix]['d_vtl_{}'.format(j)]\n",
    "        buildings.loc[group.index,'n_vtl_{}'.format(j)] = voteloc_walk_distances.loc[ix]['n_vtl_{}'.format(j)]\n",
    "        \n",
    "        buildings.loc[group.index,'d_bp_{}'.format(j)] = bike_parking_walk_distances.loc[ix]['d_bp_{}'.format(j)]\n",
    "        buildings.loc[group.index,'n_bp_{}'.format(j)] = bike_parking_walk_distances.loc[ix]['n_bp_{}'.format(j)]\n",
    "        \n",
    "        buildings.loc[group.index,'d_bs_{}'.format(j)] = bike_station_walk_distances.loc[ix]['d_bs_{}'.format(j)]\n",
    "        buildings.loc[group.index,'n_bs_{}'.format(j)] = bike_station_walk_distances.loc[ix]['n_bs_{}'.format(j)]\n",
    "        \n",
    "        buildings.loc[group.index,'d_ttcstop_{}'.format(j)] = ttc_stop_walk_distances.loc[ix]['d_ttcstop_{}'.format(j)]\n",
    "        buildings.loc[group.index,'n_ttcstop_{}'.format(j)] = ttc_stop_walk_distances.loc[ix]['n_ttcstop_{}'.format(j)]\n",
    "        \n",
    "        buildings.loc[group.index,'d_ttcst_{}'.format(j)] = ttc_station_walk_distances.loc[ix]['d_ttcst_{}'.format(j)]\n",
    "        buildings.loc[group.index,'n_ttcst_{}'.format(j)] = ttc_station_walk_distances.loc[ix]['n_ttcst_{}'.format(j)]\n",
    "        \n",
    "        buildings.loc[group.index,'d_ttcacc_{}'.format(j)] = ttc_accessible_walk_distances.loc[ix]['d_ttcacc_{}'.format(j)]\n",
    "        buildings.loc[group.index,'n_ttcacc_{}'.format(j)] = ttc_accessible_walk_distances.loc[ix]['n_ttcacc_{}'.format(j)]\n",
    "        \n",
    "        buildings.loc[group.index,'d_ts_{}'.format(j)] = ttc_accessible_walk_distances.loc[ix]['d_ts_{}'.format(j)]\n",
    "        buildings.loc[group.index,'n_ts_{}'.format(j)] = ttc_accessible_walk_distances.loc[ix]['n_ts_{}'.format(j)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate minutes fields based on distances. This can be done by adding this process to loop in the above cell.\n",
    "#This method is faster than above cell. It takes 95 seconds\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "buildings['m_fc_0'] = buildings.apply(lambda row: row.d_fc_0/(1.2*60), axis=1)\n",
    "buildings['m_fc_1'] = buildings.apply(lambda row: row.d_fc_1/(1.2*60), axis=1)\n",
    "\n",
    "buildings['m_ff_0'] = buildings.apply(lambda row: row.d_ff_0/(1.2*60), axis=1)\n",
    "buildings['m_ff_1'] = buildings.apply(lambda row: row.d_ff_1/(1.2*60), axis=1)\n",
    "\n",
    "buildings['m_sm_0'] = buildings.apply(lambda row: row.d_sm_0/(1.2*60), axis=1)\n",
    "buildings['m_sm_1'] = buildings.apply(lambda row: row.d_sm_1/(1.2*60), axis=1)\n",
    "\n",
    "buildings['m_hp_0'] = buildings.apply(lambda row: row.d_hp_0/(1.2*60), axis=1)\n",
    "buildings['m_hp_1'] = buildings.apply(lambda row: row.d_hp_1/(1.2*60), axis=1)\n",
    "\n",
    "buildings['m_sxhc_0'] = buildings.apply(lambda row: row.d_sxhc_0/(1.2*60), axis=1)\n",
    "buildings['m_sxhc_1'] = buildings.apply(lambda row: row.d_sxhc_1/(1.2*60), axis=1)\n",
    "\n",
    "buildings['m_wc_0'] = buildings.apply(lambda row: row.d_wc_0/(1.2*60), axis=1)\n",
    "buildings['m_wc_1'] = buildings.apply(lambda row: row.d_wc_1/(1.2*60), axis=1)\n",
    "\n",
    "\n",
    "buildings['m_sc_0'] = buildings.apply(lambda row: row.d_sc_0/(1.2*60), axis=1)\n",
    "buildings['m_sc_1'] = buildings.apply(lambda row: row.d_sc_1/(1.2*60), axis=1)\n",
    "\n",
    "buildings['m_ar_0'] = buildings.apply(lambda row: row.d_ar_0/(1.2*60), axis=1)\n",
    "buildings['m_ar_1'] = buildings.apply(lambda row: row.d_ar_1/(1.2*60), axis=1)\n",
    "\n",
    "buildings['m_dc_0'] = buildings.apply(lambda row: row.d_dc_0/(1.2*60), axis=1)\n",
    "buildings['m_dc_1'] = buildings.apply(lambda row: row.d_dc_1/(1.2*60), axis=1)\n",
    "\n",
    "buildings['m_di_0'] = buildings.apply(lambda row: row.d_di_0/(1.2*60), axis=1)\n",
    "buildings['m_di_1'] = buildings.apply(lambda row: row.d_di_1/(1.2*60), axis=1)\n",
    "\n",
    "buildings['m_ems_0'] = buildings.apply(lambda row: row.d_ems_0/(1.2*60), axis=1)\n",
    "buildings['m_ems_1'] = buildings.apply(lambda row: row.d_ems_1/(1.2*60), axis=1)\n",
    "\n",
    "buildings['m_frc_0'] = buildings.apply(lambda row: row.d_frc_0/(1.2*60), axis=1)\n",
    "buildings['m_frc_1'] = buildings.apply(lambda row: row.d_frc_1/(1.2*60), axis=1)\n",
    "\n",
    "\n",
    "buildings['m_fr_0'] = buildings.apply(lambda row: row.d_fr_0/(1.2*60), axis=1)\n",
    "buildings['m_fr_1'] = buildings.apply(lambda row: row.d_fr_1/(1.2*60), axis=1)\n",
    "\n",
    "buildings['m_lb_0'] = buildings.apply(lambda row: row.d_lb_0/(1.2*60), axis=1)\n",
    "buildings['m_lb_1'] = buildings.apply(lambda row: row.d_lb_1/(1.2*60), axis=1)\n",
    "\n",
    "buildings['m_plc_0'] = buildings.apply(lambda row: row.d_plc_0/(1.2*60), axis=1)\n",
    "buildings['m_plc_1'] = buildings.apply(lambda row: row.d_plc_1/(1.2*60), axis=1)\n",
    "\n",
    "buildings['m_rec_0'] = buildings.apply(lambda row: row.d_rec_0/(1.2*60), axis=1)\n",
    "buildings['m_rec_1'] = buildings.apply(lambda row: row.d_rec_1/(1.2*60), axis=1)\n",
    "\n",
    "buildings['m_thing_0'] = buildings.apply(lambda row: row.d_thing_0/(1.2*60), axis=1)\n",
    "buildings['m_thing_1'] = buildings.apply(lambda row: row.d_thing_1/(1.2*60), axis=1)\n",
    "\n",
    "buildings['m_vtl_0'] = buildings.apply(lambda row: row.d_vtl_0/(1.2*60), axis=1)\n",
    "buildings['m_vtl_1'] = buildings.apply(lambda row: row.d_vtl_1/(1.2*60), axis=1)\n",
    "\n",
    "buildings['m_bp_0'] = buildings.apply(lambda row: row.d_bp_0/(1.2*60), axis=1)\n",
    "buildings['m_bp_1'] = buildings.apply(lambda row: row.d_bp_1/(1.2*60), axis=1)\n",
    "\n",
    "buildings['m_bs_0'] = buildings.apply(lambda row: row.d_bs_0/(1.2*60), axis=1)\n",
    "buildings['m_bs_1'] = buildings.apply(lambda row: row.d_bs_1/(1.2*60), axis=1)\n",
    "\n",
    "buildings['m_ttcstop_0'] = buildings.apply(lambda row: row.d_ttcstop_0/(1.2*60), axis=1)\n",
    "buildings['m_ttcstop_1'] = buildings.apply(lambda row: row.d_ttcstop_1/(1.2*60), axis=1)\n",
    "\n",
    "buildings['m_ttcst_0'] = buildings.apply(lambda row: row.d_ttcst_0/(1.2*60), axis=1)\n",
    "buildings['m_ttcst_1'] = buildings.apply(lambda row: row.d_ttcst_1/(1.2*60), axis=1)\n",
    "\n",
    "buildings['m_ttcacc_0'] = buildings.apply(lambda row: row.d_ttcacc_0/(1.2*60), axis=1)\n",
    "buildings['m_ttcacc_1'] = buildings.apply(lambda row: row.d_ttcacc_1/(1.2*60), axis=1)\n",
    "\n",
    "buildings['m_ts_0'] = buildings.apply(lambda row: row.d_ts_0/(1.2*60), axis=1)\n",
    "buildings['m_ts_1'] = buildings.apply(lambda row: row.d_ts_1/(1.2*60), axis=1)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep wanted columns\n",
    "foodconv=foodconv[['gid', 'name','type']]\n",
    "fastfood=fastfood[['gid', 'name','type']]\n",
    "supermarket=supermarket[['gid', 'name','type']]\n",
    "hospital=hospital[['gid', 'name','type']]\n",
    "sxhclinic=sxhclinic[['gid', 'name','ward']]\n",
    "wkclinic=wkclinic[['gid', 'name','type']]\n",
    "school=school[['gid', 'name','school_type']]\n",
    "arena=arena[['gid', 'name','community']]\n",
    "daycare=daycare[['gid', 'name','place_name']]\n",
    "dropin=dropin[['gid', 'name','facility']]\n",
    "ems=ems[['gid', 'name','place_name']]\n",
    "famcentre=famcentre[['gid', 'name','agency']]\n",
    "fire=fire[['gid', 'name','address']]\n",
    "library=library[['gid', 'name','address_full']]\n",
    "police=police[['gid', 'name','address']]\n",
    "recreation=recreation[['gid', 'rc_name','rc_type']]\n",
    "thingstodo=thingstodo[['gid', 'name','td_type']]\n",
    "voteloc=voteloc[['gid', 'name','linear_nam']]\n",
    "bike_parking=bike_parking[['gid', 'address_fu','parking_ty']]\n",
    "bike_station=bike_station[['gid', 'address_fu','station_ty']]\n",
    "ttc_station=ttc_station[['gid', 'name','pt_type']]\n",
    "ttc_stop=ttc_stop[['gid', 'name','stop_code']]\n",
    "ttc_accessible=ttc_accessible[['gid', 'name','pt_type']]\n",
    "ts=ts[['gid', 'main','side_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge data takes 1065.7354395389557 seconds\n",
    "import time\n",
    "start = time.time()\n",
    "# rename the first point columns\n",
    "buildings = pd.merge(buildings, foodconv, how='left', left_on=['n_fc_0'], right_on = ['gid'] )\n",
    "buildings = buildings.rename(columns={'name': 'n_fc_0n', 'type': 'n_fc_0type'})\n",
    "\n",
    "buildings = pd.merge(buildings, fastfood, how='left', left_on=['n_ff_0'], right_on = ['gid'] )\n",
    "buildings = buildings.rename(columns={'name': 'n_ff_0n', 'type': 'n_ff_0type'})\n",
    "\n",
    "buildings = pd.merge(buildings, supermarket, how='left', left_on=['n_sm_0'], right_on = ['gid'] )\n",
    "buildings = buildings.rename(columns={'name': 'n_sm_0n', 'type': 'n_sm_0type'})\n",
    "\n",
    "buildings = pd.merge(buildings, hospital, how='left', left_on=['n_hp_0'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'name': 'n_hp_0n', 'type': 'n_hp_0type'})\n",
    "\n",
    "buildings = pd.merge(buildings, sxhclinic, how='left', left_on=['n_sxhc_0'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'name': 'n_sxhc_0n', 'ward': 'n_sxhc_0type'})\n",
    "\n",
    "buildings = pd.merge(buildings, wkclinic, how='left', left_on=['n_wc_0'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'name': 'n_wc_0n', 'type': 'n_wc_0type'})\n",
    "\n",
    "buildings = pd.merge(buildings, school, how='left', left_on=['n_sc_0'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'name': 'n_sc_0n', 'school_type': 'n_sc_0type'})\n",
    "\n",
    "buildings = pd.merge(buildings, arena, how='left', left_on=['n_ar_0'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'name': 'n_ar_0n', 'community': 'n_ar_0type'})\n",
    "\n",
    "buildings = pd.merge(buildings, library, how='left', left_on=['n_lb_0'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'name': 'n_lb_0n', 'address_full': 'n_lb_0type'})\n",
    "\n",
    "buildings = pd.merge(buildings, daycare, how='left', left_on=['n_dc_0'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'name': 'n_dc_0n', 'place_name': 'n_dc_0type'})\n",
    "\n",
    "buildings = pd.merge(buildings, fire, how='left', left_on=['n_fr_0'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'name': 'n_fr_0n', 'address': 'n_fr_0type'})\n",
    "\n",
    "buildings = pd.merge(buildings, dropin, how='left', left_on=['n_di_0'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'name': 'n_di_0n', 'facility': 'n_di_0type'})\n",
    "\n",
    "buildings = pd.merge(buildings, ems, how='left', left_on=['n_ems_0'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'name': 'n_ems_0n', 'place_name': 'n_ems_0type'})\n",
    "\n",
    "buildings = pd.merge(buildings, famcentre, how='left', left_on=['n_frc_0'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'name': 'n_frc_0n', 'agency': 'n_frc_0type'})\n",
    "\n",
    "buildings = pd.merge(buildings, police, how='left', left_on=['n_plc_0'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'name': 'n_plc_0n', 'address': 'n_plc_0type'})\n",
    "\n",
    "buildings = pd.merge(buildings, recreation, how='left', left_on=['n_rec_0'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'rc_name': 'n_rec_0n', 'rc_type': 'n_rec_0type'})\n",
    "\n",
    "buildings = pd.merge(buildings, thingstodo, how='left', left_on=['n_thing_0'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'name': 'n_thing_0n', 'td_type': 'n_thing_0type'})\n",
    "\n",
    "buildings = pd.merge(buildings, voteloc, how='left', left_on=['n_vtl_0'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'name': 'n_vtl_0n', 'linear_nam': 'n_vtl_0type'})\n",
    "\n",
    "buildings = pd.merge(buildings, bike_parking, how='left', left_on=['n_bp_0'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'adsress_fu': 'n_bp_0n', 'parking_ty': 'n_bp_0type'})\n",
    "\n",
    "buildings = pd.merge(buildings, bike_station, how='left', left_on=['n_bs_0'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'adsress_fu': 'n_bs_0n', 'station_ty': 'n_bs_0type'})\n",
    "\n",
    "buildings = pd.merge(buildings, ttc_stop, how='left', left_on=['n_ttcstop_0'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'name': 'n_ttcstop_0n', 'stop_code': 'n_ttcstop_0type'})\n",
    "\n",
    "buildings = pd.merge(buildings, ttc_station, how='left', left_on=['n_ttcst_0'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'name': 'n_ttcst_0n', 'pt_type': 'n_ttcst_0type'})\n",
    "\n",
    "buildings = pd.merge(buildings, ttc_accessible, how='left', left_on=['n_ttcacc_0'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'name': 'n_ttcacc_0n', 'pt_type': 'n_ttcacc_0type'})\n",
    "\n",
    "buildings = pd.merge(buildings, ts, how='left', left_on=['n_ts_0'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'main': 'n_ts_0n', 'side_1': 'n_ts_0type'})\n",
    "\n",
    "# rename the second point columns\n",
    "\n",
    "buildings = pd.merge(buildings, foodconv, how='left', left_on=['n_fc_1'], right_on = ['gid'] )\n",
    "buildings = buildings.rename(columns={'name': 'n_fc_1n', 'type': 'n_fc_1type'})\n",
    "\n",
    "buildings = pd.merge(buildings, fastfood, how='left', left_on=['n_ff_1'], right_on = ['gid'] )\n",
    "buildings = buildings.rename(columns={'name': 'n_ff_1n', 'type': 'n_ff_1type'})\n",
    "\n",
    "buildings = pd.merge(buildings, supermarket, how='left', left_on=['n_sm_1'], right_on = ['gid'] )\n",
    "buildings = buildings.rename(columns={'name': 'n_sm_1n', 'type': 'n_sm_1type'})\n",
    "\n",
    "buildings = pd.merge(buildings, hospital, how='left', left_on=['n_hp_1'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'name': 'n_hp_1n', 'type': 'n_hp_1type'})\n",
    "\n",
    "buildings = pd.merge(buildings, sxhclinic, how='left', left_on=['n_sxhc_1'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'name': 'n_sxhc_1n', 'ward': 'n_sxhc_1type'})\n",
    "\n",
    "buildings = pd.merge(buildings, wkclinic, how='left', left_on=['n_wc_1'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'name': 'n_wc_1n', 'type': 'n_wc_1type'})\n",
    "\n",
    "buildings = pd.merge(buildings, school, how='left', left_on=['n_sc_1'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'name': 'n_sc_1n', 'school_type': 'n_sc_1type'})\n",
    "\n",
    "buildings = pd.merge(buildings, arena, how='left', left_on=['n_ar_1'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'name': 'n_ar_1n', 'community': 'n_ar_1type'})\n",
    "\n",
    "buildings = pd.merge(buildings, library, how='left', left_on=['n_lb_1'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'name': 'n_lb_1n', 'address_full': 'n_lb_1type'})\n",
    "\n",
    "buildings = pd.merge(buildings, daycare, how='left', left_on=['n_dc_1'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'name': 'n_dc_1n', 'place_name': 'n_dc_1type'})\n",
    "\n",
    "buildings = pd.merge(buildings, fire, how='left', left_on=['n_fr_1'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'name': 'n_fr_1n', 'address': 'n_fr_1type'})\n",
    "\n",
    "buildings = pd.merge(buildings, dropin, how='left', left_on=['n_di_1'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'name': 'n_di_1n', 'facility': 'n_di_1type'})\n",
    "\n",
    "buildings = pd.merge(buildings, ems, how='left', left_on=['n_ems_1'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'name': 'n_ems_1n', 'place_name': 'n_ems_1type'})\n",
    "\n",
    "buildings = pd.merge(buildings, famcentre, how='left', left_on=['n_frc_1'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'name': 'n_frc_1n', 'agency': 'n_frc_1type'})\n",
    "\n",
    "buildings = pd.merge(buildings, police, how='left', left_on=['n_plc_1'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'name': 'n_plc_1n', 'address': 'n_plc_1type'})\n",
    "\n",
    "buildings = pd.merge(buildings, recreation, how='left', left_on=['n_rec_1'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'rc_name': 'n_rec_1n', 'rc_type': 'n_rec_1type'})\n",
    "\n",
    "buildings = pd.merge(buildings, thingstodo, how='left', left_on=['n_thing_1'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'name': 'n_thing_1n', 'td_type': 'n_thing_1type'})\n",
    "\n",
    "buildings = pd.merge(buildings, voteloc, how='left', left_on=['n_vtl_1'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'name': 'n_vtl_1n', 'linear_nam': 'n_vtl_1type'})\n",
    "\n",
    "buildings = pd.merge(buildings, bike_parking, how='left', left_on=['n_bp_1'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'adsress_fu': 'n_bp_1n', 'parking_ty': 'n_bp_1type'})\n",
    "\n",
    "buildings = pd.merge(buildings, bike_station, how='left', left_on=['n_bs_1'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'adsress_fu': 'n_bs_1n', 'station_ty': 'n_bs_1type'})\n",
    "\n",
    "buildings = pd.merge(buildings, ttc_stop, how='left', left_on=['n_ttcstop_1'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'name': 'n_ttcstop_1n', 'stop_code': 'n_ttcstop_1type'})\n",
    "\n",
    "buildings = pd.merge(buildings, ttc_station, how='left', left_on=['n_ttcst_1'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'name': 'n_ttcst_1n', 'pt_type': 'n_ttcst_1type'})\n",
    "\n",
    "buildings = pd.merge(buildings, ttc_accessible, how='left', left_on=['n_ttcacc_1'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'name': 'n_ttcacc_1n', 'pt_type': 'n_ttcacc_1type'})\n",
    "\n",
    "buildings = pd.merge(buildings, ts, how='left', left_on=['n_ts_1'], right_on = ['gid']) \n",
    "buildings = buildings.rename(columns={'main': 'n_ts_1n', 'side_1': 'n_ts_1type'})\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see all the columns\n",
    "print(buildings.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#at last drop unwanted columns baased on the columns\n",
    "buildings.drop(['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1', 'Unnamed: 0.1.1.1', 'gid_x', 'node_ids', 'stype_x', 'gid_y', 'x_y', 'y_y',\n",
    "                'stype_y', 'gid_x.1', 'x_x.1', 'y_x.1', 'stype_x.1', 'gid_y.1', 'x_y.1', 'y_y.1', 'gid_x.2', 'x_x.2', 'y_x.2', 'gid_y.2',\n",
    "                'x_y.2', 'y_y.2', 'gid_x.3',  'school_type_x', 'gid_y.3', 'gid_x.4', 'x_x.3', 'y_x.3', 'x_y.3', 'y_y.3', 'gid_y.4',\n",
    "                'gid_x.5', 'x_x.4', 'y_x.4', 'gid_y.5' , 'x_y.4', 'y_y.4', 'gid_x.6', 'x_x.5', 'y_x.5' , 'gid_y.6', 'x_y.5', 'y_y.5',\n",
    "                'gid_x.7', 'x_x.6', 'y_x.6', 'gid_y.7', 'x_y.6', 'y_y.6', 'gid_x.8', 'name_x', 'x_x.7', 'y_x.7',  'gid_y.8', 'x_y.7',\n",
    "                'y_y.7',  'name_y', 'gid_x.9', 'x_x.8', 'y_x.8', 'gid_y.9', 'address_fu_x', 'name_x.1', 'x_y.8', 'y_y.8',  'gid_x.10',\n",
    "                'address_fu_y', 'name_y.1', 'x_x.9', 'y_x.9', 'x_y.9', 'y_y.9', 'gid_y.10', 'x_x.10', 'y_x.10', 'gid_x.11', 'x_y.10',\n",
    "                'y_y.10',  'gid_y.11', 'x_x.11', 'y_x.11', 'stype_y.1', 'gid_x.12', 'x_y.11', 'y_y.11', 'stype_x.2', 'gid_y.12', 'x_x.12',\n",
    "                'y_x.12', 'stype_y.2', 'gid_x.13', 'x_y.12', 'y_y.12',  'gid_y.13',  'x_x.13', 'y_x.13', 'gid_x.14', 'x_y.13', 'y_y.13',\n",
    "                'gid_y.14', 'school_type_y', 'gid_x.15', 'gid_y.15', 'x_x.14', 'y_x.14', 'community', 'gid_x.16', 'x_y.14', 'y_y.14',\n",
    "                'x_x.15', 'y_x.15', 'gid_y.16', 'gid_x.17', 'x_y.15', 'y_y.15', 'gid_y.17', 'x_x.16', 'y_x.16', 'gid_x.18', 'x_y.16',\n",
    "                'y_y.16', 'gid_y.18', 'x_x.17', 'y_x.17', 'gid_x.19', 'x_y.17', 'y_y.17', 'gid_y.19', 'name_x.2', 'x_x.18', 'y_x.18',\n",
    "                'gid_x.20', 'x_y.18', 'y_y.18', 'name_y.2', 'gid_y.20', 'x_x.19', 'y_x.19', 'gid_x.21', 'address_fu_x.1', 'name_x.3',\n",
    "                'x_y.19', 'y_y.19', 'gid_y.21', 'address_fu_y.1', 'name_y.3', 'x_x.20', 'y_x.20', 'x_y.20', 'y_y.20', 'gid_x.22', 'x_x.21',\n",
    "                'y_x.21', 'gid_y.22', 'x_y.21', 'y_y.21', 'gid'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(buildings.columns.values)\n",
    "['Unnamed: 0' 'ctuid' 'ctname' 'ctnum' 'geotext' 'geom' 'node_ids'\n",
    " 'd_fc_0' 'n_fc_0' 'd_ff_0' 'n_ff_0' 'd_sm_0' 'n_sm_0' 'd_hp_0' 'n_hp_0'\n",
    " 'd_sxhc_0' 'n_sxhc_0' 'd_wc_0' 'n_wc_0' 'd_sc_0' 'n_sc_0' 'd_ar_0'\n",
    " 'n_ar_0' 'd_dc_0' 'n_dc_0' 'd_di_0' 'n_di_0' 'd_ems_0' 'n_ems_0' 'd_fc_1'\n",
    " 'n_fc_1' 'd_ff_1' 'n_ff_1' 'd_sm_1' 'n_sm_1' 'd_hp_1' 'n_hp_1' 'd_sxhc_1'\n",
    " 'n_sxhc_1' 'd_wc_1' 'n_wc_1' 'd_sc_1' 'n_sc_1' 'd_ar_1' 'n_ar_1' 'd_dc_1'\n",
    " 'n_dc_1' 'd_di_1' 'n_di_1' 'd_ems_1' 'n_ems_1' 'd_frc_0' 'n_frc_0'\n",
    " 'd_fr_0' 'n_fr_0' 'd_lb_0' 'n_lb_0' 'd_plc_0' 'n_plc_0' 'd_rec_0'\n",
    " 'n_rec_0' 'd_thing_0' 'n_thing_0' 'd_vtl_0' 'n_vtl_0' 'd_bp_0' 'n_bp_0'\n",
    " 'd_bs_0' 'n_bs_0' 'd_ttcstop_0' 'n_ttcstop_0' 'd_ttcst_0' 'n_ttcst_0'\n",
    " 'd_ttcacc_0' 'n_ttcacc_0' 'd_ts_0' 'n_ts_0' 'd_frc_1' 'n_frc_1' 'd_fr_1'\n",
    " 'n_fr_1' 'd_lb_1' 'n_lb_1' 'd_plc_1' 'n_plc_1' 'd_rec_1' 'n_rec_1'\n",
    " 'd_thing_1' 'n_thing_1' 'd_vtl_1' 'n_vtl_1' 'd_bp_1' 'n_bp_1' 'd_bs_1'\n",
    " 'n_bs_1' 'd_ttcstop_1' 'n_ttcstop_1' 'd_ttcst_1' 'n_ttcst_1' 'd_ttcacc_1'\n",
    " 'n_ttcacc_1' 'd_ts_1' 'n_ts_1' 'm_fc_0' 'm_fc_1' 'm_ff_0' 'm_ff_1'\n",
    " 'm_sm_0' 'm_sm_1' 'm_hp_0' 'm_hp_1' 'm_sxhc_0' 'm_sxhc_1' 'm_wc_0'\n",
    " 'm_wc_1' 'm_sc_0' 'm_sc_1' 'm_ar_0' 'm_ar_1' 'm_dc_0' 'm_dc_1' 'm_di_0'\n",
    " 'm_di_1' 'm_ems_0' 'm_ems_1' 'm_frc_0' 'm_frc_1' 'm_fr_0' 'm_fr_1'\n",
    " 'm_lb_0' 'm_lb_1' 'm_plc_0' 'm_plc_1' 'm_rec_0' 'm_rec_1' 'm_thing_0'\n",
    " 'm_thing_1' 'm_vtl_0' 'm_vtl_1' 'm_bp_0' 'm_bp_1' 'm_bs_0' 'm_bs_1'\n",
    " 'm_ttcstop_0' 'm_ttcstop_1' 'm_ttcst_0' 'm_ttcst_1' 'm_ttcacc_0'\n",
    " 'm_ttcacc_1' 'm_ts_0' 'm_ts_1' 'n_fc_0n' 'n_fc_0type' 'n_ff_0n'\n",
    " 'n_ff_0type' 'n_sm_0n' 'n_sm_0type' 'n_hp_0n' 'n_hp_0type' 'n_sxhc_0n'\n",
    " 'n_sxhc_0type' 'n_wc_0n' 'n_wc_0type' 'n_sc_0n' 'n_sc_0type' 'n_ar_0n'\n",
    " 'n_ar_0type' 'n_lb_0n' 'n_lb_0type' 'n_dc_0n' 'n_dc_0type' 'n_fr_0n'\n",
    " 'n_fr_0type' 'n_di_0.1' 'n_dc_0type.1' 'n_ems_0n' 'n_ems_0type'\n",
    " 'n_frc_0n' 'n_frc_0type' 'n_plc_0n' 'n_plc_0type' 'n_rec_0n'\n",
    " 'n_rec_0type' 'n_thing_0n' 'n_thing_0type' 'n_vtl_0n' 'n_vtl_0type'\n",
    " 'n_bp_0type' 'n_bs_0type' 'n_ttcstop_0n' 'n_ttcstop_0type' 'n_ttcst_0n'\n",
    " 'n_ttcst_0type' 'n_ttcacc_0n' 'n_ttcacc_0type' 'n_ts_0n' 'n_ts_0type'\n",
    " 'n_fc_1n' 'n_fc_1type' 'n_ff_1n' 'n_ff_1type' 'n_sm_1n' 'n_sm_1type'\n",
    " 'n_hp_1n' 'n_hp_1type' 'n_sxhc_1n' 'n_sxhc_1type' 'n_wc_1n' 'n_wc_1type'\n",
    " 'n_sc_1n' 'n_sc_1type' 'n_ar_1n' 'n_ar_1type' 'n_lb_1n' 'n_lb_1type'\n",
    " 'n_dc_1n' 'n_dc_1type' 'n_fr_1n' 'n_fr_1type' 'n_di_1.1' 'n_dc_1type.1'\n",
    " 'n_ems_1n' 'n_ems_1type' 'n_frc_1n' 'n_frc_1type' 'n_plc_1n'\n",
    " 'n_plc_1type' 'n_rec_1n' 'n_rec_1type' 'n_thing_1n' 'n_thing_1type'\n",
    " 'n_vtl_1n' 'n_vtl_1type' 'n_bp_1type' 'n_bs_1type' 'n_ttcstop_1n'\n",
    " 'n_ttcstop_1type' 'n_ttcst_1n' 'n_ttcst_1type' 'n_ttcacc_1n'\n",
    " 'n_ttcacc_1type' 'gid' 'n_ts_1n' 'n_ts_1type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating SQLAlchemy's engine to use\n",
    "engine = create_engine('postgresql://postgres:****@****:5432/walkability')\n",
    "\n",
    "buildings['geometry'] = buildings['geom'].apply(lambda x: WKTElement(x.wkt, srid=2019))\n",
    "\n",
    "#drop the geometry column as it is now duplicative\n",
    "blds= buildings.drop('geom', 1, inplace=False)\n",
    "\n",
    "# Use 'dtype' to specify column's type\n",
    "# For the geom column, we will use GeoAlchemy's type 'Geometry'\n",
    "blds.to_sql(\"buildings527\", engine, if_exists='replace', index=False, \n",
    "                         dtype={'geometry': Geometry('MULTIPOLYGON', srid= 2019)})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
